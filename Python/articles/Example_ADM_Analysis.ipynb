{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "## Link to article\n",
    "\n",
    "This notebook is included in the documentation, where the interactive Plotly charts show up. See:\n",
    "https://pegasystems.github.io/pega-datascientist-tools/Python/articles/Example_ADM_Analysis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example ADM analysis\n",
    "See this notebook for an introduction to the ADMDatamart class to get an overview of the currently implemented features in the Python version of CDH Tools. If you have any suggestions for new features, please do not hesitate to raise an issue in Git, or even better: create a pull request yourself!\n",
    "\n",
    "This notebook builds upon the [Getting Started guide](https://github.com/pegasystems/pega-datascientist-tools/wiki#using-the-python-tools). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "Reading the data is quite simple. All you need to do is to give a directory location to the ADMSnapshot class and it will automatically detect the latest files and import them. There is also a default function to import the CDH Sample data directly from the internet, as you can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:02.328330Z",
     "iopub.status.busy": "2024-05-16T15:40:02.327932Z",
     "iopub.status.idle": "2024-05-16T15:40:02.398833Z",
     "shell.execute_reply": "2024-05-16T15:40:02.398293Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# These lines are only for rendering in the docs, and are hidden through Jupyter tags\n",
    "# Do not run if you're running the notebook seperately\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:02.400905Z",
     "iopub.status.busy": "2024-05-16T15:40:02.400568Z",
     "iopub.status.idle": "2024-05-16T15:40:03.294057Z",
     "shell.execute_reply": "2024-05-16T15:40:03.293425Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pdstools.utils.NBAD' has no attribute 'NBAD_prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdstools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADMDatamart, datasets\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m CDHSample \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mCDHSample()\n",
      "File \u001b[0;32m~/work/pega-datascientist-tools/pega-datascientist-tools/python/docs/source/articles/../../../pdstools/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpega_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m File, API, S3\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpega_io\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAPI\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setupAzureOpenAI\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprediction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prediction\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdh_utils, datasets, errors, hds_utils\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcdh_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultPredictorCategorization\n",
      "File \u001b[0;32m~/work/pega-datascientist-tools/pega-datascientist-tools/python/docs/source/articles/../../../pdstools/prediction/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPrediction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prediction\n",
      "File \u001b[0;32m~/work/pega-datascientist-tools/pega-datascientist-tools/python/docs/source/articles/../../../pdstools/prediction/Prediction.py:7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdh_utils, NBAD\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mPrediction\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# These are pretty strict conditions - many configurations appear not to satisfy these\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# perhaps the Total = Test + Control is no longer met when Impact Analyzer is around\u001b[39;49;00m\n",
      "File \u001b[0;32m~/work/pega-datascientist-tools/pega-datascientist-tools/python/docs/source/articles/../../../pdstools/prediction/Prediction.py:30\u001b[0m, in \u001b[0;36mPrediction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# These are pretty strict conditions - many configurations appear not to satisfy these\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# perhaps the Total = Test + Control is no longer met when Impact Analyzer is around\u001b[39;00m\n\u001b[1;32m     12\u001b[0m validityExpr \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     13\u001b[0m     (pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositives\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m&\u001b[39m (pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositives_Test\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetPredictionsChannelMapping\u001b[39m(\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m, custom_predictions\u001b[38;5;241m=\u001b[39mList[\u001b[43mNBAD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNBAD_prediction\u001b[49m]\n\u001b[1;32m     31\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pl\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m     32\u001b[0m     all_mappings \u001b[38;5;241m=\u001b[39m NBAD\u001b[38;5;241m.\u001b[39mstandardNBADPredictions \u001b[38;5;241m+\u001b[39m custom_predictions\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pl\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     34\u001b[0m         {\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: [x\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m all_mappings],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m         }\n\u001b[1;32m     41\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pdstools.utils.NBAD' has no attribute 'NBAD_prediction'"
     ]
    }
   ],
   "source": [
    "from pdstools import ADMDatamart, datasets\n",
    "import polars as pl\n",
    "\n",
    "CDHSample = datasets.CDHSample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations\n",
    "The following visualisations are currently available in the python version of CDH Tools. See the table below for which visualisations are applicable to what types of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.296212Z",
     "iopub.status.busy": "2024-05-16T15:40:03.296036Z",
     "iopub.status.idle": "2024-05-16T15:40:03.306875Z",
     "shell.execute_reply": "2024-05-16T15:40:03.306448Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mAvailableVisualisations\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.AvailableVisualisations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, every visualisation needs modelData, a few also need predictorData, and plotPerformanceAndSuccessRateOverTime, plotOverTime and plotResponseCountMatrix are the only visualisations requiring multiple snapshots.\n",
    "\n",
    "Let's quickly go over some easy ones to see what it does below. To start out with the bubble chart, which we can simply call by calling plotPerformanceSuccessRateBubbleChart with our main class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.308786Z",
     "iopub.status.busy": "2024-05-16T15:40:03.308616Z",
     "iopub.status.idle": "2024-05-16T15:40:03.319589Z",
     "shell.execute_reply": "2024-05-16T15:40:03.319035Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mplotPerformanceSuccessRateBubbleChart()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.plotPerformanceSuccessRateBubbleChart()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a healthy bubble plot, but sometimes it is useful to consider only certain models in the analysis. Note that the bubble chart automatically considers only the last snapshot by default, though this is a parameter. \n",
    "\n",
    "To reduce the information, let's only consider models with more than 500 responses within the CreditCards group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.321644Z",
     "iopub.status.busy": "2024-05-16T15:40:03.321385Z",
     "iopub.status.idle": "2024-05-16T15:40:03.332765Z",
     "shell.execute_reply": "2024-05-16T15:40:03.332314Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query \u001b[38;5;241m=\u001b[39m (\u001b[43mpl\u001b[49m\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponseCount\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m) \u001b[38;5;241m&\u001b[39m (pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreditCards\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m CDHSample\u001b[38;5;241m.\u001b[39mplotPerformanceSuccessRateBubbleChart(query\u001b[38;5;241m=\u001b[39mquery)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "query = (pl.col(\"ResponseCount\") > 500) & (pl.col(\"Group\") == \"CreditCards\")\n",
    "CDHSample.plotPerformanceSuccessRateBubbleChart(query=query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could only look at the top n best performing models within our query. To do this, we need to supply a list of model IDs which we can easily extract from the data as such.\n",
    "\n",
    "Note here the alternative querying syntax you can use, which was default in the previous version of CDH Tools: if you have a list (list) to subset a column's values with, you can simply supply a dictionary with 'column name':list to only get values in that list for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.334624Z",
     "iopub.status.busy": "2024-05-16T15:40:03.334451Z",
     "iopub.status.idle": "2024-05-16T15:40:03.347395Z",
     "shell.execute_reply": "2024-05-16T15:40:03.346822Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m top30ids \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mlast(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlazy\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerformance\u001b[39m\u001b[38;5;124m\"\u001b[39m, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mto_series()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m CDHSample\u001b[38;5;241m.\u001b[39mplotPerformanceSuccessRateBubbleChart(query\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelID\u001b[39m\u001b[38;5;124m\"\u001b[39m: top30ids})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "top30ids = (\n",
    "    CDHSample.last(strategy='lazy').sort(\"Performance\", descending=True)\n",
    "    .select(\"ModelID\")\n",
    "    .head(30)\n",
    "    .collect()\n",
    "    .to_series()\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "CDHSample.plotPerformanceSuccessRateBubbleChart(query={\"ModelID\": top30ids})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bubble chart gives some information about which models perform well, but that is not always informative: if we don't know in which channels, issues or groups our issues lie then we may not be looking in the right place. This is where the Treemap visualisation is quite handy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.349371Z",
     "iopub.status.busy": "2024-05-16T15:40:03.349041Z",
     "iopub.status.idle": "2024-05-16T15:40:03.359684Z",
     "shell.execute_reply": "2024-05-16T15:40:03.359230Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mplotTreeMap()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.plotTreeMap()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the Treemap shows the weighted performance, where the performance is weighted by the response count. The squares represent Model IDs: the larger a square, the more model IDs are within that combination of context keys. We can also color the Treemap by another variable, such as the SuccessRate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.361727Z",
     "iopub.status.busy": "2024-05-16T15:40:03.361412Z",
     "iopub.status.idle": "2024-05-16T15:40:03.372048Z",
     "shell.execute_reply": "2024-05-16T15:40:03.371594Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mplotTreeMap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessRate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.plotTreeMap(\"SuccessRate\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the responses, the success rate over time can also be of interest. With 'plotOverTime', you can plot the success rate of different models as they develop over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.374163Z",
     "iopub.status.busy": "2024-05-16T15:40:03.373768Z",
     "iopub.status.idle": "2024-05-16T15:40:03.385151Z",
     "shell.execute_reply": "2024-05-16T15:40:03.384637Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mplotOverTime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessRate\u001b[39m\u001b[38;5;124m\"\u001b[39m, by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelID\u001b[39m\u001b[38;5;124m\"\u001b[39m, query\u001b[38;5;241m=\u001b[39mpl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChannel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.plotOverTime(\"SuccessRate\", by=\"ModelID\", query=pl.col(\"Channel\") == \"Web\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if it is not interesting to consider the success rate over time, there is also 'plotPropositionSuccessRates', which by default considers the last state of the models and plots the histogram of their success rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.387172Z",
     "iopub.status.busy": "2024-05-16T15:40:03.386845Z",
     "iopub.status.idle": "2024-05-16T15:40:03.397928Z",
     "shell.execute_reply": "2024-05-16T15:40:03.397471Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mplotPropositionSuccessRates(query\u001b[38;5;241m=\u001b[39mpl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChannel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.plotPropositionSuccessRates(query=pl.col(\"Channel\") == \"Web\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to look at the distribution of responses and their propensities for a given model, we can subset that model and call plotScoreDistribution. Note here we subset the model by its ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.399951Z",
     "iopub.status.busy": "2024-05-16T15:40:03.399635Z",
     "iopub.status.idle": "2024-05-16T15:40:03.410572Z",
     "shell.execute_reply": "2024-05-16T15:40:03.410120Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mplotScoreDistribution(\n\u001b[1;32m      2\u001b[0m     query\u001b[38;5;241m=\u001b[39mpl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelID\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m08ca1302-9fc0-57bf-9031-d4179d400493\u001b[39m\u001b[38;5;124m\"\u001b[39m, show_each\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.plotScoreDistribution(\n",
    "    query=pl.col(\"ModelID\") == \"08ca1302-9fc0-57bf-9031-d4179d400493\", show_each=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also subset a model by its model name, and then further drill down by group/issue/channel/configuration. See the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.412649Z",
     "iopub.status.busy": "2024-05-16T15:40:03.412321Z",
     "iopub.status.idle": "2024-05-16T15:40:03.424947Z",
     "shell.execute_reply": "2024-05-16T15:40:03.424339Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mplotScoreDistribution(\n\u001b[1;32m      2\u001b[0m     query\u001b[38;5;241m=\u001b[39m(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHomeOwners\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m&\u001b[39m (pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBundles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m&\u001b[39m (pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIssue\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m&\u001b[39m (pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChannel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m&\u001b[39m (pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfiguration\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOmniAdaptiveModel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.plotScoreDistribution(\n",
    "    query=(pl.col(\"Name\") == \"HomeOwners\")\n",
    "    & (pl.col(\"Group\") == \"Bundles\")\n",
    "    & (pl.col(\"Issue\") == \"Sales\")\n",
    "    & (pl.col(\"Channel\") == \"Web\")\n",
    "    & (pl.col(\"Configuration\") == \"OmniAdaptiveModel\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can also display the distribution of a single predictor and its binning. This function loops through each predictor of a model and generates the binning image for that predictor. For that reason we recommend subsetting the predictor names ahead of time or, depending on how many predictors the model has, a lot of images will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.427108Z",
     "iopub.status.busy": "2024-05-16T15:40:03.426712Z",
     "iopub.status.idle": "2024-05-16T15:40:03.492573Z",
     "shell.execute_reply": "2024-05-16T15:40:03.491871Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mplotPredictorBinning(\n\u001b[1;32m      2\u001b[0m     query\u001b[38;5;241m=\u001b[39m(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelID\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m08ca1302-9fc0-57bf-9031-d4179d400493\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m&\u001b[39m (\n\u001b[1;32m      4\u001b[0m         pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictorName\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mis_in(\n\u001b[1;32m      5\u001b[0m             [\n\u001b[1;32m      6\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer.Age\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer.AnnualIncome\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIH.Email.Outbound.Accepted.pxLastGroupID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m             ]\n\u001b[1;32m     10\u001b[0m         )\n\u001b[1;32m     11\u001b[0m     ),\n\u001b[1;32m     12\u001b[0m     show_each\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m );\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.plotPredictorBinning(\n",
    "    query=(pl.col(\"ModelID\") == \"08ca1302-9fc0-57bf-9031-d4179d400493\")\n",
    "    & (\n",
    "        pl.col(\"PredictorName\").is_in(\n",
    "            [\n",
    "                \"Customer.Age\",\n",
    "                \"Customer.AnnualIncome\",\n",
    "                \"IH.Email.Outbound.Accepted.pxLastGroupID\",\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    show_each=True,\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can look at the performance of a predictor over multiple models. Again, we recommend subsetting the predictor names with a list to make it more legible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.495075Z",
     "iopub.status.busy": "2024-05-16T15:40:03.494685Z",
     "iopub.status.idle": "2024-05-16T15:40:03.508236Z",
     "shell.execute_reply": "2024-05-16T15:40:03.507688Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mplotPredictorPerformance(\n\u001b[1;32m      2\u001b[0m     query\u001b[38;5;241m=\u001b[39mpl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictorName\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mis_in(\n\u001b[1;32m      3\u001b[0m         [\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer.Age\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer.AnnualIncome\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIH.Email.Outbound.Accepted.pxLastGroupID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m         ]\n\u001b[1;32m      8\u001b[0m     ))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.plotPredictorPerformance(\n",
    "    query=pl.col(\"PredictorName\").is_in(\n",
    "        [\n",
    "            \"Customer.Age\",\n",
    "            \"Customer.AnnualIncome\",\n",
    "            \"IH.Email.Outbound.Accepted.pxLastGroupID\",\n",
    "        ]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the two previous visualisations could not represent very well is the performance of the predictors over different models. That is what the plotPredictorPerformanceHeatmap function does; again with subsetting of predictors as a recommended step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:40:03.510514Z",
     "iopub.status.busy": "2024-05-16T15:40:03.510338Z",
     "iopub.status.idle": "2024-05-16T15:40:03.525873Z",
     "shell.execute_reply": "2024-05-16T15:40:03.525294Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CDHSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCDHSample\u001b[49m\u001b[38;5;241m.\u001b[39mplotPredictorPerformanceHeatmap(\n\u001b[1;32m      2\u001b[0m     query\u001b[38;5;241m=\u001b[39mpl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictorName\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mis_in(\n\u001b[1;32m      3\u001b[0m         [\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer.Age\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer.AnnualIncome\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIH.Email.Outbound.Accepted.pxLastGroupID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m         ]\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CDHSample' is not defined"
     ]
    }
   ],
   "source": [
    "CDHSample.plotPredictorPerformanceHeatmap(\n",
    "    query=pl.col(\"PredictorName\").is_in(\n",
    "        [\n",
    "            \"Customer.Age\",\n",
    "            \"Customer.AnnualIncome\",\n",
    "            \"IH.Email.Outbound.Accepted.pxLastGroupID\",\n",
    "        ]\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
